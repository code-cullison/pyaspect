{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the records from the Geom Test of Reciprocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0\n",
    "\n",
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all packages\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from sys import argv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "from pyaspect.project import *\n",
    "from pyaspect.model.gridmod3d import gridmod3d as gm\n",
    "from pyaspect.model.bbox import bbox as bb\n",
    "from pyaspect.model.gm3d_utils import *\n",
    "from pyaspect.moment_tensor import MomentTensor\n",
    "from pyaspect.specfemio.headers import *\n",
    "from pyaspect.specfemio.write import *\n",
    "from pyaspect.specfemio.write import _write_header\n",
    "from pyaspect.specfemio.read import _read_headers\n",
    "from pyaspect.specfemio.read import *\n",
    "from pyaspect.specfemio.utils import *\n",
    "\n",
    "\n",
    "import pyaspect.events.gevents as gevents\n",
    "import pyaspect.events.gstations as gstations\n",
    "from pyaspect.events.munge.knmi import correct_station_depths as csd_f\n",
    "import pyaspect.events.mtensors as mtensors\n",
    "from obspy.imaging.beachball import beach\n",
    "from obspy import UTCDateTime\n",
    "import shapefile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Project Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_dir  = 'data/output/'\n",
    "data_out_dir = data_in_dir\n",
    "!ls {data_out_dir}/tmp/TestProjects/CGFR_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_fqp = os.path.join(data_out_dir,'tmp','TestProjects','CGFR_Test')\n",
    "recip_project_fqp = os.path.join(projects_fqp,'ReciprocalGeometricTestProject')\n",
    "fwd_project_fqp = os.path.join(projects_fqp,'ForwardGeometricTestProject')\n",
    "!ls {recip_project_fqp}\n",
    "print()\n",
    "!ls {fwd_project_fqp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define bandpass (this is just a secondary test to sos filter) (taken from scipy recipies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Reciprocal Project RecordHeader and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(self,dtype,sl=slice(None,None,None),scale=1.0,rfunc=None):\n",
    "    \n",
    "    if dtype != 'b':\n",
    "        raise Exception('can only read binary type data for the time being')\n",
    "\n",
    "    l_data_x = []\n",
    "    l_data_y = []\n",
    "    l_data_z = []\n",
    "    for idx, row in self.stations_df.iterrows():\n",
    "        fp_prefix = row['data_fqdn']\n",
    "        fp = os.path.join(projects_fqp,fp_prefix) \n",
    "        match_fp = fp + '.*X[XYZEN].sem*'\n",
    "        for filepath in glob.glob(match_fp):\n",
    "            comp = filepath.split('.')[-2][-1]\n",
    "            fname = filepath.split(\"/\")[-1]\n",
    "            if comp == 'X' or comp == 'E':\n",
    "                l_data_x.append(scale*(np.fromfile(filepath, dtype=np.float32)[sl].astype(np.float64)))\n",
    "            elif comp == 'Y' or comp == 'N':\n",
    "                l_data_y.append(scale*(np.fromfile(filepath, dtype=np.float32)[sl].astype(np.float64)))\n",
    "            elif comp == 'Z':\n",
    "                l_data_z.append(scale*(np.fromfile(filepath, dtype=np.float32)[sl].astype(np.float64)))\n",
    "            else:\n",
    "                raise Exception(f'Could not find component: \"{comp}\"')\n",
    "                \n",
    "    df_ne = self.stations_df.index.get_level_values('eid').nunique()\n",
    "    df_ns = self.stations_df.index.get_level_values('sid').nunique()\n",
    "    df_ns = self.stations_df.index.get_level_values('sid').nunique()\n",
    "    '''\n",
    "    for eidx, edf in recip_record_h.stations_df.groupby(level='eid'):\n",
    "        for sidx, sdf in edf.groupby(level='sid'):\n",
    "            for tidx, tdf in sdf.groupby(level='trid'):\n",
    "                for gidx, tdf in tdf.groupby(level='gid'):\n",
    "    '''\n",
    "\n",
    "    self.stations_df['comp_EX'] = l_data_x\n",
    "    self.stations_df['comp_NY'] = l_data_y\n",
    "    self.stations_df['comp_Z']  = l_data_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "recip_record_fqp = os.path.join(recip_project_fqp,'pyheader.project_record')\n",
    "recip_record_h = _read_headers(recip_record_fqp)\n",
    "\n",
    "ne = recip_record_h.nevents\n",
    "ns = recip_record_h.nsrc\n",
    "print(f'ne:{ne}, ns:{ns}')\n",
    "\n",
    "_load_data(recip_record_h,'b',scale=1.0,sl=slice(None,-10,None))\n",
    "\n",
    "print(f'Recip Header:\\n{recip_record_h}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for computing the derivatives and applying the bandpass to reciprocal traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calulate_spacial_derivative(tdf,eidx,sidx,tidx,g_p1,g_m1,sos,comp_key,coord_key):\n",
    "    gidx_0  = pd.IndexSlice[eidx,sidx,tidx,0]\n",
    "    gidx_p1 = pd.IndexSlice[eidx,sidx,tidx,g_p1]\n",
    "    gidx_m1 = pd.IndexSlice[eidx,sidx,tidx,g_m1]\n",
    "    df_0    = tdf.loc[gidx_0]\n",
    "    df_p1   = tdf.loc[gidx_p1]\n",
    "    df_m1   = tdf.loc[gidx_m1]\n",
    "    data_p1 = signal.sosfilt(sos, df_p1[comp_key])\n",
    "    data_m1 = signal.sosfilt(sos, df_m1[comp_key])\n",
    "    c_p1    = df_p1[coord_key]\n",
    "    c_m1    = df_m1[coord_key]\n",
    "    c_0     = df_0[coord_key]\n",
    "    delta   = 0.5*(c_p1 - c_m1)\n",
    "    h       = 2.0*np.abs(delta)\n",
    "    c       = c_m1 + delta\n",
    "    \n",
    "    assert h != 0\n",
    "    assert c_0-c == 0\n",
    "    \n",
    "    h_scale  = 1/h\n",
    "    mt_trace = h_scale*(data_p1 - data_m1)\n",
    "    \n",
    "    return mt_trace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar to cell directly above, but calculate full 9D Greens Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delta = 50\n",
    "comp_dict = {'comp_EX':0,'comp_NY':1,'comp_Z':2}\n",
    "coord_dict = {0:'lon_xc',1:'lat_yc',2:'depth'}\n",
    "sos = signal.butter(3, [1,10], 'bp', fs=1000, output='sos') #USE for fwd and Recip\n",
    "#sos = signal.butter(4, 10, 'lp', fs=1000, output='sos') #USE for fwd and Recip\n",
    "\n",
    "ne = recip_record_h.nevents\n",
    "ng = 9    #num sations\n",
    "nc = 3    #num components (x=0,y=1,z=0)\n",
    "nf = 3    #num force-directions (ex=0,ny=1,zup=2)\n",
    "nd = 3    #num direction/derivatives (d_ex=0,d_ny=1,d_zup=2)\n",
    "nt = 4096-10 #num samples in trace/greens function (hard coded for testing only)\n",
    "rgf_table = np.zeros((ne,ng,nc,nf,nd,nt),dtype=np.float64)\n",
    "\n",
    "src_df = recip_record_h.solutions_df\n",
    "l_trace_latlon = []\n",
    "l_event_latlon = []\n",
    "for eidx, edf in recip_record_h.stations_df.groupby(level='eid'):\n",
    "    for sidx, sdf in edf.groupby(level='sid'):\n",
    "        jdx = (eidx,sidx)\n",
    "        if sidx == 0:\n",
    "            l_trace_latlon.append([jdx,src_df.loc[jdx,\"lon_xc\"],src_df.loc[jdx,\"lat_yc\"]])\n",
    "        for tidx, tdf in sdf.groupby(level='trid'):\n",
    "            idx = (eidx,sidx,tidx,0)\n",
    "            if sidx == 0 and eidx == 0:\n",
    "                l_event_latlon.append([idx,tdf.loc[idx,\"lon_xc\"],tdf.loc[idx,\"lat_yc\"]])\n",
    "            for comp_key in comp_dict.keys():\n",
    "                ie = tidx\n",
    "                ig = eidx\n",
    "                ic = comp_dict[comp_key]\n",
    "                fi = sidx\n",
    "                \n",
    "                # dx=0,dy=1,dz=2\n",
    "                d = delta\n",
    "                for di in range(3):\n",
    "                    coord_key = coord_dict[di]\n",
    "                    ip1 = di+1     #coord + h\n",
    "                    im1 = ip1 + 3  #coord - h\n",
    "                    if di == 2:\n",
    "                        tm1 = ip1\n",
    "                        ip1 = im1\n",
    "                        im1 = tm1\n",
    "                        #d = -delta #FIXME: This is FUGLY!\n",
    "                    rgf_table[ie,ig,ic,fi,di,:] = calulate_spacial_derivative(tdf,eidx,sidx,tidx,ip1,im1,sos,comp_key,coord_key)\n",
    "                \n",
    "#assert False               \n",
    "print(f'l_event_latlon:')\n",
    "for evn in l_event_latlon:\n",
    "    print(evn)\n",
    "print()\n",
    "print(f'l_trace_latlon:')\n",
    "for trc in l_trace_latlon:\n",
    "    print(trc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and compare table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Forward Record and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_record_fqp = os.path.join(fwd_project_fqp,'pyheader.project_record')\n",
    "fwd_record_h = _read_headers(fwd_record_fqp)\n",
    "\n",
    "ne = fwd_record_h.nevents\n",
    "ns = fwd_record_h.nsrc\n",
    "print(f'ne:{ne}, ns:{ns}')\n",
    "\n",
    "#_load_data(fwd_record_h,'b',scale=1E7,sl=slice(10,None,None))\n",
    "_load_data(fwd_record_h,'b',scale=1.0,sl=slice(10,None,None))\n",
    "\n",
    "print(f'Forward Record:\\n{fwd_record_h}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspec moment tensors from Forward event. Will use thise for making Reciprocal Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_moment_tensor(src_h):\n",
    "    \n",
    "    mrr = src_h['mrr']\n",
    "    mtt = src_h['mtt']\n",
    "    mpp = src_h['mpp']\n",
    "    mrt = src_h['mrt']\n",
    "    mrp = src_h['mrp']\n",
    "    mtp = src_h['mtp']\n",
    "    \n",
    "    h_matrix = np.array([[mrr,mrt,mrp],[mrt,mtt,mtp],[mrp,mtp,mpp]])\n",
    "    \n",
    "    return MomentTensor(m_up_south_east=h_matrix)\n",
    "\n",
    "\n",
    "#print(f'Forward Record Sources:\\n{fwd_record_h.solutions_df}')\n",
    "SrcHeader = fwd_record_h.solution_cls\n",
    "\n",
    "d_fwd_src = {}\n",
    "for eidx, edf in fwd_record_h.solutions_df.groupby(level='eid'):\n",
    "    for sidx, sdf in edf.groupby(level='sid'):\n",
    "        idx = pd.IndexSlice[eidx,sidx]\n",
    "        src = SrcHeader.from_series(fwd_record_h.solutions_df.loc[idx])\n",
    "        #print(src)\n",
    "        #mag    = src.mw\n",
    "        #strike = src.strike\n",
    "        #dip    = src.dip\n",
    "        #rake   = src.rake\n",
    "        #mt = MomentTensor(mw=mag,strike=strike,dip=dip,rake=rake)\n",
    "        mt = make_moment_tensor(src)\n",
    "        print(mt)\n",
    "        d_fwd_src[eidx] = mt\n",
    "        #print(f'mt.aki_m6:\\n{mt.aki_richards_m6()}')\n",
    "        #print(f'header.m6:\\n{src.mt}\\n')\n",
    "\n",
    "for key in d_fwd_src:\n",
    "    print(d_fwd_src[key].m6_up_south_east())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive the x,y, and z components for each event from the sorted reciprocity traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr = 9\n",
    "ne  = 7\n",
    "nc  = 3\n",
    "nt  = 4096 - 10\n",
    "\n",
    "cmb_traces = np.zeros((ne,ntr,nc,nt),dtype=np.float64)\n",
    "for ie in range(ne):\n",
    "    #print(f'mt:\\n{d_fwd_src[ie]}')\n",
    "    mw = d_fwd_src[ie].magnitude\n",
    "    m0    = d_fwd_src[ie].moment\n",
    "    #mt_arr = d_fwd_src[ie].m6_up_south_east()/m0\n",
    "    mt_arr = d_fwd_src[ie].m6_up_south_east()\n",
    "    wzz =  mt_arr[0] #mrr\n",
    "    wyy =  mt_arr[1] #mtt\n",
    "    wxx =  mt_arr[2] #mpp\n",
    "    wyz = -mt_arr[3] #mrt\n",
    "    wxz =  mt_arr[4] #mrp\n",
    "    wxy = -mt_arr[5] #mtp\n",
    "    \n",
    "    #print(f'wuu:{wzz}, wnn:{wyy}, wee:{wxx}, wnu:{wyz}, weu:{wxz}, wen:{wxy}')\n",
    "    print(f'Mw:{mw:.2f}, M0:{m0:.2f}, wzz:{wzz:.3f}, wyy:{wyy:.3f}, wee:{wxx:.3f}, wxy:{wxy:.3f}, wxz:{wxz:.3f}, wyz:{wyz:.3f}')\n",
    "    \n",
    "    for it in range(ntr):\n",
    "        icomp = 0\n",
    "        for comp_key in ['comp_EX','comp_NY','comp_Z']:\n",
    "            \n",
    "                                              #rgf_table[ie,it,ic,  fi ,di,:] \n",
    "            cmb_traces[ie,it,icomp,:] += wxx*1*rgf_table[ie,it, 0,icomp, 0,:] #Matrix: Mee\n",
    "            cmb_traces[ie,it,icomp,:] += wyy*1*rgf_table[ie,it, 1,icomp, 1,:] #Matrix: Mnn\n",
    "            cmb_traces[ie,it,icomp,:] += wzz*1*rgf_table[ie,it, 2,icomp, 2,:] #Matrix: Mzz\n",
    "            \n",
    "            #Matrix: M1/Mxy\n",
    "            cmb_traces[ie,it,icomp,:] += wxy*1*rgf_table[ie,it, 1,icomp, 0,:]\n",
    "            cmb_traces[ie,it,icomp,:] += wxy*1*rgf_table[ie,it, 0,icomp, 1,:]\n",
    "            \n",
    "            #Matrix: M2/Mxz\n",
    "            cmb_traces[ie,it,icomp,:] += wxz*1*rgf_table[ie,it, 0,icomp, 2,:]\n",
    "            cmb_traces[ie,it,icomp,:] += wxz*1*rgf_table[ie,it, 2,icomp, 0,:]\n",
    "            \n",
    "            #Matrix: M3/Myz\n",
    "            cmb_traces[ie,it,icomp,:] += wyz*1*rgf_table[ie,it, 1,icomp, 2,:]\n",
    "            cmb_traces[ie,it,icomp,:] += wyz*1*rgf_table[ie,it, 2,icomp, 1,:]\n",
    "            \n",
    "            icomp += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bandpass the \"forward\" traces to match the bandpass of the reciprocal traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne = 7\n",
    "ntr = 9\n",
    "nc = 3\n",
    "nt = 4096 - 10\n",
    "fwd_traces = np.zeros((ne,ntr,nc,nt))\n",
    "\n",
    "for eidx, edf in fwd_record_h.stations_df.groupby(level='eid'):\n",
    "    for sidx, sdf in edf.groupby(level='sid'):\n",
    "        for tidx, tdf in sdf.groupby(level='trid'):\n",
    "            idx = pd.IndexSlice[eidx,sidx,tidx,0]\n",
    "            ic = 0\n",
    "            for comp_key in ['comp_EX','comp_NY','comp_Z']:\n",
    "                fwd_traces[eidx,tidx,ic,:] =  signal.sosfilt(sos, tdf.loc[idx,comp_key])\n",
    "                ic += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the \"forward\" traces (black) on top of the reciprocal constructed traces (fat-blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "rcomp_dict = {0:'E/X',1:'N/Y',2:'Z'}\n",
    "\n",
    "ne  = 7\n",
    "ntr = 9\n",
    "nc  = 3\n",
    "nplt = ne*ntr*nc \n",
    "fig, axs = plt.subplots(nplt,1,figsize=(15,4*nplt))\n",
    "fig.subplots_adjust(hspace=.75)\n",
    "\n",
    "ip = 0\n",
    "for ie in range(ne):\n",
    "    for itr in range(ntr):\n",
    "        for ic in range(nc):\n",
    "            int_cmb_traces = 0.0001*np.cumsum(cmb_traces[ie,itr,ic,:].copy())\n",
    "            #recip_max = np.max(np.abs(int_cmb_traces))\n",
    "            #comp_traces = int_cmb_traces/recip_max\n",
    "            comp_traces =  int_cmb_traces\n",
    "            #axs[ip].plot(comp_traces,linewidth=2,linestyle='--',zorder=0,label='Recip')\n",
    "            axs[ip].plot(comp_traces,color='gold',alpha=0.5,linestyle='-',linewidth=2,zorder=1,label='Recip')\n",
    "            cmt_traces = fwd_traces[ie,itr,ic,:].copy()\n",
    "            #cmt_traces /= np.max(np.abs(cmt_traces))\n",
    "            #cmt_traces = np.cumsum(fwd_traces[ie,itr,ic,:].copy()) # if velocity\n",
    "            #fwd_max = np.max(np.abs(cmt_traces))\n",
    "            #cmt_traces /= fwd_max\n",
    "            #print(f'fwd_max: {fwd_max}\\nrecip_max: {recip_max}\\nr/f: {recip_max/fwd_max}')\n",
    "            '''\n",
    "            div_traces = np.zeros_like(cmt_traces)\n",
    "            for i in range(len(div_traces)):\n",
    "                if cmt_traces[i] != 0:\n",
    "                    div_traces[i] = comp_traces[i]/cmt_traces[i]\n",
    "                else:\n",
    "                    div_traces[i] = 1.0\n",
    "            '''\n",
    "            #axs[ip].plot(div_traces,color='orange',linewidth=2,zorder=0,label='CMT')\n",
    "            axs[ip].plot(cmt_traces*2.3,color='lightblue',alpha=0.5,linewidth=5,zorder=0,label='CMT')\n",
    "            axs[ip].set_title(f'Event:{ie}, Trace:{itr}, Comp:{rcomp_dict[ic]}')\n",
    "            '''\n",
    "            if itr == 3:\n",
    "                print(f'Trace-3:\\n{fwd_record_h[ie,0,itr,0]}')\n",
    "            ''';\n",
    "            ip += 1\n",
    "\n",
    "#assert ip == nplt\n",
    "plt.show()\n",
    "\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.3**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4/np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[2,0,0],[0,4,0],[0,0,6]])\n",
    "s = 1/np.sqrt(2)\n",
    "y = s*np.sqrt(np.sum(x*x))\n",
    "print(y)\n",
    "print(x/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _XYZ(object):\n",
    "\n",
    "    def __init__(self,ex,ny,z):\n",
    "\n",
    "        self.ex = ex\n",
    "        self.ny = ny\n",
    "        self.z  = z\n",
    "\n",
    "    '''\n",
    "    @property\n",
    "    def ex(self):\n",
    "        return self.ex\n",
    "\n",
    "    @property\n",
    "    def ny(self):\n",
    "        return self.ny\n",
    "\n",
    "    @property\n",
    "    def z(self):\n",
    "        return self.z\n",
    "    '''\n",
    "        \n",
    "class Cdata(object):\n",
    "    \n",
    "    def __init__(self,ax,ay,az):\n",
    "        \n",
    "        self.ax = ax\n",
    "        self.ay = ay\n",
    "        self.az = az\n",
    "        \n",
    "    def __getitem__(self,islice):\n",
    "        return _XYZ(self.ax[islice],self.ay[islice],self.az[islice])\n",
    "\n",
    "    @property\n",
    "    def ex(self):\n",
    "        return self.ax\n",
    "\n",
    "    @property\n",
    "    def ny(self):\n",
    "        return self.ay\n",
    "\n",
    "    @property\n",
    "    def z(self):\n",
    "        return self.az\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "idata = Cdata(np.arange(10,20), np.arange(20,30), np.arange(30,40))\n",
    "\n",
    "print(f'{ idata[::-1].ex == idata.ex[::-1] }')\n",
    "print(f'{ idata[5::2].ny == idata.ny[5::2] }')\n",
    "print(f'{ idata[:8:-3].z == idata.z[:8:-3] }')\n",
    "\n",
    "x = idata[::-1].ex.copy()\n",
    "y = idata[::-1].ex.copy()\n",
    "y[0] = -1\n",
    "if all( x == y ):\n",
    "    print('yep')\n",
    "    print( x == y )\n",
    "else:\n",
    "    print('nope')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
