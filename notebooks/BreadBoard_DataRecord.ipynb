{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bread Board Constrcut record.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyaspect.moment_tensor import MomentTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_dir  = 'data/output/'\n",
    "data_out_dir = data_in_dir\n",
    "!ls {data_out_dir}/tmp/TestProjects/CGFR_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_fqp = os.path.join(data_out_dir,'tmp','TestProjects','CGFR_Test')\n",
    "recip_project_fqp = os.path.join(projects_fqp,'ReciprocalGeometricTestProject')\n",
    "fwd_project_fqp = os.path.join(projects_fqp,'ForwardGeometricTestProject')\n",
    "!ls {recip_project_fqp}\n",
    "print()\n",
    "!ls {fwd_project_fqp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyaspect.specfemio.headers import RecordHeader\n",
    "\n",
    "#TODO this is the actual record. I need the header, then make record.py\n",
    "class Record(RecordHeader):\n",
    "\n",
    "            \n",
    "\n",
    "    class _TraceData(object):\n",
    "        \n",
    "        class _XYZ(object):\n",
    "\n",
    "            def __init__(self,ex,ny,z):\n",
    "\n",
    "                self.ex = ex\n",
    "                self.ny = ny\n",
    "                self.z  = z\n",
    "\n",
    "            def __str__(self):\n",
    "                out_str  = f'Component E/X:\\n{self.ex}\\n\\n'\n",
    "                out_str += f'Component N/Y:\\n{self.ny}\\n\\n'\n",
    "                out_str += f'Component Z:\\n{self.z}'\n",
    "                return out_str\n",
    "\n",
    "            def __repr__(self):\n",
    "                out_str  = f'Component E/X:\\n{self.ex.__repr__()}\\n\\n'\n",
    "                out_str += f'Component N/Y:\\n{self.ny.__repr__()}\\n\\n'\n",
    "                out_str += f'Component Z:\\n{self.z.__repr__()}'\n",
    "                return out_str\n",
    "\n",
    "\n",
    "        def __init__(self,data_df):\n",
    "            \n",
    "            self.df_x = data_df['comp_EX']\n",
    "            self.df_y = data_df['comp_NY']\n",
    "            self.df_z = data_df['comp_Z']\n",
    "\n",
    "\n",
    "        def __getitem__(self,islice):\n",
    "            return self._XYZ(self.df_x.loc[islice],self.df_y.loc[islice],self.df_z.loc[islice])\n",
    "\n",
    "        def __str__(self):\n",
    "            out_str  = f'Component E/X:\\n{self.df_x}\\n\\n'\n",
    "            out_str += f'Component N/Y:\\n{self.df_y}\\n\\n'\n",
    "            out_str += f'Component Z:\\n{self.df_z}'\n",
    "            return out_str\n",
    "\n",
    "        def __repr__(self):\n",
    "            out_str  = f'Component E/X:\\n{self.df_x.__repr__()}\\n\\n'\n",
    "            out_str += f'Component N/Y:\\n{self.df_y.__repr__()}\\n\\n'\n",
    "            out_str += f'Component Z:\\n{self.df_z.__repr__()}'\n",
    "            return out_str\n",
    "        \n",
    "            \n",
    "\n",
    "    def __init__(self, rheader,dtype='b',data_df=None):\n",
    "        super(Record,self).__init__(name=rheader.name,\n",
    "                                    solutions_h=rheader.get_solutions_header_list(),\n",
    "                                    stations_h=rheader.get_stations_header_list(),\n",
    "                                    proj_id=rheader.proj_id,\n",
    "                                    rid=rheader.rid,\n",
    "                                    iter_id=rheader.iter_id,\n",
    "                                    is_reciprocal=rheader.is_reciprocal)\n",
    "        \n",
    "        if not isinstance(data_df,pd.DataFrame):\n",
    "            self._load_data(dtype=dtype)\n",
    "        else:\n",
    "            self['data_df'] = data_df\n",
    "            \n",
    "\n",
    "    def __str__(self):\n",
    "        out_str  = f'{super(Record, self).__str__()}\\n\\n'\n",
    "        out_str += f'Data:\\n {self.data_df}'\n",
    "        return out_str\n",
    "    \n",
    "    def __repr__(self):\n",
    "        out_str  = f'{super(Record, self).__repr__()}\\n\\n'\n",
    "        out_str += f'Data:\\n {self.data_df.__repr__()}'\n",
    "        return out_str\n",
    "    \n",
    "    def __getitem__(self, kslice):\n",
    "        \n",
    "        if not isinstance(kslice, str):\n",
    "            dslice = super(Record, self)._get_df_slice_index(kslice,self.data_df,is_stations=True)\n",
    "            c_data_df = self.data_df.reset_index()[dslice]\n",
    "            c_rheader = super(Record, self).__getitem__(kslice)\n",
    "            return Record(rheader=c_rheader,data_df=c_data_df)\n",
    "        else:\n",
    "            return super(Record, self).__getitem__(kslice)\n",
    "    \n",
    "    def _read_specfem_bin_trace(self,fpath,dtype=np.float32):\n",
    "        return np.fromfile(fpath, dtype=dtype)\n",
    "\n",
    "    def _load_data(self,dtype='b',sl=slice(None,None,None),scale=1.0,rfunc=None):\n",
    "\n",
    "        if dtype != 'b' and _rfunc == None:\n",
    "            raise Exception('can only read binary type data for the time being')\n",
    "            \n",
    "        #FIXME: add read ascii\n",
    "        read_func = self._read_specfem_bin_trace\n",
    "        if rfunc != None:\n",
    "            read_func = rfunc\n",
    "\n",
    "        l_data = []\n",
    "        for eidx, edf in self.stations_df.groupby(level='eid'):\n",
    "            for sidx, sdf in edf.groupby(level='sid'):\n",
    "                for tidx, tdf in sdf.groupby(level='trid'):\n",
    "                    for gidx, gdf in tdf.groupby(level='gid'):\n",
    "                        fp_prefix = gdf.loc[(eidx,sidx,tidx,gidx),\"data_fqdn\"]\n",
    "                        fp = os.path.join(projects_fqp,fp_prefix)\n",
    "                        match_fp = fp + '.*X[XYZEN].sem*'\n",
    "                        data_dict = {'eid':eidx,'sid':sidx,'trid':tidx,'gid':gidx}\n",
    "                        for filepath in glob.glob(match_fp):\n",
    "                            comp = filepath.split('.')[-2][-1]\n",
    "                            if comp == 'X' or comp == 'E':\n",
    "                                data_dict['comp_EX'] = scale*read_func(filepath)\n",
    "                            elif comp == 'Y' or comp == 'N':\n",
    "                                data_dict['comp_NY'] = scale*read_func(filepath)\n",
    "                            elif comp == 'Z':\n",
    "                                data_dict['comp_Z'] = scale*read_func(filepath)\n",
    "                            else:\n",
    "                                raise Exception(f'Could not find component: \"{comp}\"')\n",
    "                                \n",
    "                        l_data.append(data_dict)\n",
    "                            \n",
    "        self['data_df'] = pd.DataFrame.from_records(l_data, index=self['default_stat_midx'])\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._TraceData(self.data_df)\n",
    "        \n",
    "    @property\n",
    "    def data_df(self):\n",
    "        return self['data_df']\n",
    "    \n",
    "    @property\n",
    "    def component_names(self):\n",
    "        return ['comp_EX','comp_NY','comp_Z']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reciprocity: Read RecordHeader and instantiate RecordObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pyaspect.specfemio.read import _read_headers\n",
    "\n",
    "recip_record_fqp = os.path.join(recip_project_fqp,'pyheader.project_record')\n",
    "recip_record_h = _read_headers(recip_record_fqp)\n",
    "\n",
    "recip_record_h.is_reciprocal = True #just a hack until updated\n",
    "\n",
    "ne = recip_record_h.nevents\n",
    "ns = recip_record_h.nsrc\n",
    "\n",
    "print(f'ne:{ne}, ns:{ns}')\n",
    "print(f'Recip Header:\\n{recip_record_h.solutions_df.loc[pd.IndexSlice[:,1],:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Record, and test slicing and pandas operations with DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recip_record = Record(recip_record_h)\n",
    "#print(recip_drecord['is_reciprocal'])\n",
    "#print(recip_drecord.data_df.loc[(0,0,0),:])\n",
    "#print(recip_drecord.data_df.loc[:,'comp_EX'])\n",
    "#print(recip_drecord[0,0,0,:])\n",
    "data = recip_record.data\n",
    "#print(type(data[0,0,0,0].z))\n",
    "#print(data)\n",
    "print(pd.merge(recip_record.stations_df,recip_record.data_df,on=['eid','sid','trid','gid']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trace spacial derivative function to add to records.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def calulate_spacial_derivative(tdf,eidx,sidx,tidx,g_p1,g_m1,sos,comp_key,coord_key):\n",
    "    gidx_0  = pd.IndexSlice[eidx,sidx,tidx,0]\n",
    "    gidx_p1 = pd.IndexSlice[eidx,sidx,tidx,g_p1]\n",
    "    gidx_m1 = pd.IndexSlice[eidx,sidx,tidx,g_m1]\n",
    "    df_0    = tdf.loc[gidx_0]\n",
    "    df_p1   = tdf.loc[gidx_p1]\n",
    "    df_m1   = tdf.loc[gidx_m1]\n",
    "    data_p1 = signal.sosfilt(sos, df_p1[comp_key].astype(np.float64))\n",
    "    data_m1 = signal.sosfilt(sos, df_m1[comp_key].astype(np.float64))\n",
    "    c_p1    = df_p1[coord_key]\n",
    "    c_m1    = df_m1[coord_key]\n",
    "    c_0     = df_0[coord_key]\n",
    "    delta   = 0.5*(c_p1 - c_m1)\n",
    "    h       = 2.0*np.abs(delta)\n",
    "    c       = c_m1 + delta\n",
    "    \n",
    "    assert h != 0\n",
    "    assert c_0-c == 0\n",
    "    \n",
    "    h_scale  = 1/h\n",
    "    mt_trace = h_scale*(data_p1 - data_m1)\n",
    "    \n",
    "    return mt_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make reciprocal Green's functions: add to record.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "def make_rgf_data_df(record,fl,fh,fs):\n",
    "\n",
    "    comp_dict = {'comp_EX':0,'comp_NY':1,'comp_Z':2}\n",
    "    coord_dict = {0:'lon_xc',1:'lat_yc',2:'depth'}\n",
    "    sos = signal.butter(3, [fl,fh], 'bp', fs=fs, output='sos') \n",
    "\n",
    "    l_rgf_traces = []\n",
    "    m_df = pd.merge(record.stations_df,record.data_df,on=['eid','sid','trid','gid'])\n",
    "    for eidx, edf in m_df.groupby(level='eid'):\n",
    "        for sidx, sdf in edf.groupby(level='sid'):\n",
    "            for tidx, tdf in sdf.groupby(level='trid'):\n",
    "                for comp_key in comp_dict.keys():\n",
    "                    ie = tidx\n",
    "                    ig = eidx\n",
    "                    fi = sidx\n",
    "                    for di in range(3):\n",
    "                        rgf_dict = {'eid':tidx,'trid':eidx,'fid':sidx}\n",
    "                        rgf_dict['cid'] = comp_dict[comp_key]\n",
    "                        coord_key = coord_dict[di]\n",
    "                        rgf_dict['did'] = di\n",
    "                        ip1 = di+1     #coord + h\n",
    "                        im1 = ip1 + 3  #coord - h\n",
    "                        if di == 2:\n",
    "                            tm1 = ip1\n",
    "                            ip1 = im1\n",
    "                            im1 = tm1\n",
    "                        rgf_dict['data'] = calulate_spacial_derivative(m_df,\n",
    "                                                                       eidx,\n",
    "                                                                       sidx,\n",
    "                                                                       tidx,\n",
    "                                                                       ip1,\n",
    "                                                                       im1,\n",
    "                                                                       sos,\n",
    "                                                                       comp_key,\n",
    "                                                                       coord_key)\n",
    "                        \n",
    "                        l_rgf_traces.append(rgf_dict)\n",
    "                    \n",
    "    return pd.DataFrame.from_records(l_rgf_traces, index=('eid','trid','cid','fid','did'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create Reciprocal Green's Table (as DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgf_data_df = make_rgf_data_df(recip_record,1.0,10.0,1000)\n",
    "rgf_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(rgf_df)\n",
    "print(rgf_data_df.loc[0,0,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward/CMTSolution: Read RecordHeader and instantiate RecordObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fwd_record_fqp = os.path.join(fwd_project_fqp,'pyheader.project_record')\n",
    "fwd_record_h = _read_headers(fwd_record_fqp)\n",
    "\n",
    "fwd_record_h.is_reciprocal = False #just a hack until updated\n",
    "\n",
    "ne = fwd_record_h.nevents\n",
    "ns = fwd_record_h.nsrc\n",
    "\n",
    "print(f'ne:{ne}, ns:{ns}')\n",
    "print(f'Forward Record:\\n{fwd_record_h.solutions_df.loc[(0,0),\"date\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Forward Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_record = Record(fwd_record_h)\n",
    "#print(fwd_record['is_reciprocal'])\n",
    "#print(fwd_record.data_df.loc[(0,0,0),:])\n",
    "#print(fwd_record.data_df.loc[:,'comp_EX'])\n",
    "#print(fwd_record[0,0,0,:])\n",
    "data = fwd_record.data\n",
    "#print(type(data[0,0,0,0].z))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment tensors to compare with Foward data and also Construct Combinded Reciprocal CMTs. These functions will not be part of record.py module, but make_moment_tensor will be added to utils.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_moment_tensor(src_h):\n",
    "    \n",
    "    mrr = src_h['mrr']\n",
    "    mtt = src_h['mtt']\n",
    "    mpp = src_h['mpp']\n",
    "    mrt = src_h['mrt']\n",
    "    mrp = src_h['mrp']\n",
    "    mtp = src_h['mtp']\n",
    "    \n",
    "    h_matrix = np.array([[mrr,mrt,mrp],[mrt,mtt,mtp],[mrp,mtp,mpp]])\n",
    "    \n",
    "    return MomentTensor(m_up_south_east=h_matrix)\n",
    "\n",
    "\n",
    "#print(f'Forward Record Sources:\\n{fwd_record_h.solutions_df}')\n",
    "SrcHeader = fwd_record_h.solution_cls\n",
    "\n",
    "d_fwd_src = {}\n",
    "for eidx, edf in fwd_record_h.solutions_df.groupby(level='eid'):\n",
    "    for sidx, sdf in edf.groupby(level='sid'):\n",
    "        idx = pd.IndexSlice[eidx,sidx]\n",
    "        src = SrcHeader.from_series(fwd_record_h.solutions_df.loc[idx])\n",
    "        #print(src)\n",
    "        #mag    = src.mw\n",
    "        #strike = src.strike\n",
    "        #dip    = src.dip\n",
    "        #rake   = src.rake\n",
    "        #mt = MomentTensor(mw=mag,strike=strike,dip=dip,rake=rake)\n",
    "        mt = make_moment_tensor(src)\n",
    "        print(mt)\n",
    "        d_fwd_src[eidx] = mt\n",
    "        #print(f'mt.aki_m6:\\n{mt.aki_richards_m6()}')\n",
    "        #print(f'header.m6:\\n{src.mt}\\n')\n",
    "\n",
    "for key in d_fwd_src:\n",
    "    print(d_fwd_src[key].m6_up_south_east())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Reciprocal CMT record from MomentTensors Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cmt_data_df_from_rgf(rgf_df,mt_dict):\n",
    "    \n",
    "    comp_dict = {'comp_EX':0,'comp_NY':1,'comp_Z':2}\n",
    "    \n",
    "    rgf_events = list(rgf_df.index.get_level_values('eid').unique())\n",
    "    #print(f'rgf_events: {rgf_events}')\n",
    "    mt_events  = list(mt_dict.keys())\n",
    "    #print(f'mt_events: {mt_events}')\n",
    "    #print(f'all: {rgf_events == mt_events}')\n",
    "    \n",
    "    if not rgf_events == mt_events:\n",
    "        raise Exception('RGF-events do not match MomentTensors-events')\n",
    "    \n",
    "    l_recip_cmt_traces = []\n",
    "    for eidx, edf in rgf_df.groupby(level='eid'):\n",
    "        \n",
    "        mw = d_fwd_src[eidx].magnitude\n",
    "        m0 = d_fwd_src[eidx].moment\n",
    "        mt_arr = d_fwd_src[eidx].m6_up_south_east()\n",
    "        \n",
    "        wzz =  mt_arr[0] #mrr\n",
    "        wyy =  mt_arr[1] #mtt\n",
    "        wxx =  mt_arr[2] #mpp\n",
    "        wyz = -mt_arr[3] #mrt\n",
    "        wxz =  mt_arr[4] #mrp\n",
    "        wxy = -mt_arr[5] #mtp\n",
    "        \n",
    "        #print(f'Mw:{mw:.2f}, M0:{m0:.2f}, wzz:{wzz:.3f}, wyy:{wyy:.3f}, wee:{wxx:.3f}, wxy:{wxy:.3f}, wxz:{wxz:.3f}, wyz:{wyz:.3f}')\n",
    "    \n",
    "        \n",
    "        for tidx, tdf in edf.groupby(level='trid'):\n",
    "            d_recip_cmt = {'eid':eidx,'sid':eidx,'trid':tidx,'gid':0}\n",
    "            for comp_key in comp_dict.keys():\n",
    "                ic = comp_dict[comp_key]\n",
    "                \n",
    "                composite_trace  = wxx*1*rgf_df.loc[(eidx,tidx, 0,ic, 0),'data'] #Matrix: Mee\n",
    "                composite_trace += wyy*1*rgf_df.loc[(eidx,tidx, 1,ic, 1),'data'] #Matrix: Mnn\n",
    "                composite_trace += wzz*1*rgf_df.loc[(eidx,tidx, 2,ic, 2),'data'] #Matrix: Mzz\n",
    "\n",
    "                #Matrix: M1/Mxy\n",
    "                composite_trace += wxy*1*rgf_df.loc[(eidx,tidx, 1,ic, 0),'data']\n",
    "                composite_trace += wxy*1*rgf_df.loc[(eidx,tidx, 0,ic, 1),'data']\n",
    "\n",
    "                #Matrix: M2/Mxz\n",
    "                composite_trace += wxz*1*rgf_df.loc[(eidx,tidx, 0,ic, 2),'data']\n",
    "                composite_trace += wxz*1*rgf_df.loc[(eidx,tidx, 2,ic, 0),'data']\n",
    "\n",
    "                #Matrix: M3/Myz\n",
    "                composite_trace += wyz*1*rgf_df.loc[(eidx,tidx, 1,ic, 2),'data']\n",
    "                composite_trace += wyz*1*rgf_df.loc[(eidx,tidx, 2,ic, 1),'data']\n",
    "                \n",
    "                d_recip_cmt[comp_key] = composite_trace\n",
    "                \n",
    "            l_recip_cmt_traces.append(d_recip_cmt)\n",
    "        \n",
    "    return pd.DataFrame.from_records(l_recip_cmt_traces, index=('eid','sid','trid','gid'))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Dataframe with the Reciprocal CMT Traces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rgf_cmt_data_df = make_cmt_data_df_from_rgf(rgf_data_df,d_fwd_src)\n",
    "for eidx, edf in rgf_cmt_data_df.groupby(level='eid'):\n",
    "    print(eidx)\n",
    "\n",
    "print(rgf_cmt_data_df.loc[pd.IndexSlice[0,0,:,0],:])\n",
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Reciprocal CMT RecordHeader and then a Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from pyaspect.specfemio.headers import CMTSolutionHeader as cmt_h\n",
    "from pyaspect.specfemio.headers import StationHeader     as stat_h\n",
    "'''\n",
    "hstr  = f'PDE {date.year} {date.month} {date.day} {date.hour} {date.minute} {date.second}'\n",
    "hstr += f' {lat_yc} {lon_xc} {depth/1000.0} {mt.magnitude} 0 srcid_{eid}'\n",
    "'''\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "solu_df = recip_record.solutions_df\n",
    "stat_df = recip_record.stations_df\n",
    "l_recip_cmtsolutions = []\n",
    "l_recip_cmtstations  = []\n",
    "proj_id = recip_record.proj_id\n",
    "for eidx, edf in rgf_cmt_data_df.groupby(level='eid'):\n",
    "    eid    = eidx\n",
    "    print(f'eid: {eid}')\n",
    "    mt     = d_fwd_src[eid]\n",
    "    for tidx, tdf in edf.groupby(level='trid'):\n",
    "        date      = datetime.datetime.now()\n",
    "        lon_xc    = solu_df.loc[(eidx,0),'lon_xc']\n",
    "        lat_yc    = solu_df.loc[(eidx,0),'lat_yc']\n",
    "        depth     = solu_df.loc[(eidx,0),'depth']\n",
    "        elevation = 0.\n",
    "        network   = stat_df.loc[(tidx,0,eidx,0),'network']\n",
    "        stat_header = stat_h(name=f'Reciprocal-Station:{tidx}',\n",
    "                             lat_yc=lat_yc,\n",
    "                             lon_xc=lon_xc,\n",
    "                             depth=depth,\n",
    "                             elevation=elevation,\n",
    "                             network=network,\n",
    "                             proj_id=proj_id,\n",
    "                             eid=eid,\n",
    "                             sid=eid,\n",
    "                             trid=tidx,\n",
    "                             gid=0)\n",
    "        l_recip_cmtstations.append(stat_header)\n",
    "        cmt_lon_xc    = stat_df.loc[(tidx,0,eidx,0),'lon_xc']\n",
    "        cmt_lat_yc    = stat_df.loc[(tidx,0,eidx,0),'lat_yc']\n",
    "        cmt_depth     = stat_df.loc[(tidx,0,eidx,0),'depth']\n",
    "            \n",
    "    cmt_header = cmt_h(ename=f'Reciprocal-CMT:{eid}',\n",
    "                       lat_yc=cmt_lat_yc,\n",
    "                       lon_xc=cmt_lon_xc,\n",
    "                       depth=cmt_depth,\n",
    "                       tshift=0,\n",
    "                       date=date,\n",
    "                       hdur=0,\n",
    "                       mt=mt,\n",
    "                       proj_id=proj_id,\n",
    "                       eid=eid,\n",
    "                       sid=eid)\n",
    "\n",
    "    l_recip_cmtsolutions.append(cmt_header)\n",
    "    \n",
    "constructed_record = RecordHeader(name=f'Reciprocal of:{recip_record.name}',\n",
    "                                  solutions_h=l_recip_cmtsolutions,\n",
    "                                  stations_h=l_recip_cmtstations,\n",
    "                                  proj_id=proj_id,\n",
    "                                  rid=recip_record.rid,\n",
    "                                  iter_id=recip_record.iter_id,\n",
    "                                  is_reciprocal=False)\n",
    "\n",
    "#sid0_df['eid','name'].apply((lambda x: x+1)())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructed_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
