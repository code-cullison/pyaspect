{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Test of Reciprocity of 3 Sources and 3 Recievers in Groningen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0\n",
    "\n",
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all packages\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from sys import argv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "\n",
    "from pyaspect.project import *\n",
    "from pyaspect.model.gridmod3d import gridmod3d as gm\n",
    "from pyaspect.model.bbox import bbox as bb\n",
    "from pyaspect.model.gm3d_utils import *\n",
    "from pyaspect.moment_tensor import MomentTensor\n",
    "from pyaspect.specfemio.headers import *\n",
    "from pyaspect.specfemio.write import *\n",
    "from pyaspect.specfemio.write import _write_header\n",
    "from pyaspect.specfemio.read import *\n",
    "from pyaspect.specfemio.utils import *\n",
    "\n",
    "\n",
    "import pyaspect.events.gevents as gevents\n",
    "import pyaspect.events.gstations as gstations\n",
    "from pyaspect.events.munge.knmi import correct_station_depths as csd_f\n",
    "import pyaspect.events.mtensors as mtensors\n",
    "from obspy.imaging.beachball import beach\n",
    "from obspy import UTCDateTime\n",
    "import shapefile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 \n",
    "\n",
    "Extract the ndarray of the subsampled, smoothed NAM model and instantiate a new GriddedModel3D object for QC'ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_dir  = 'data/output/'\n",
    "data_out_dir = data_in_dir\n",
    "!ls {data_in_dir}\n",
    "!ls data/groningen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 \n",
    "\n",
    "Decompress the ndarray of the sliced, subsampled, smoothed NAM model and instantiate a new GriddedModel3D object for QC'ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filename then used it to decompress model\n",
    "ifqn = f'{data_out_dir}/vsliced_subsmp_smth_nam_2017_vp_vs_rho_Q_model_dx100_dy100_dz100_maxdepth5850_sig250.npz'\n",
    "vslice_gm3d, other_pars = decompress_gm3d_from_file(ifqn)\n",
    "\n",
    "print()\n",
    "print('decompressed gridded model\\n:',vslice_gm3d) \n",
    "print()\n",
    "print('other parameters:\\n',other_pars)\n",
    "print()\n",
    "\n",
    "# WARNING: this will unpack all other_pars, if you overwrite a variable of the samename as val(key), then you \n",
    "#          may not notice, and this may cause large headaches.  I use it because I am aware of it.\n",
    "'''\n",
    "for key in other_pars:\n",
    "    locals()[key] = other_pars[key]  #this is more advanced python than I think is reasonable for most \n",
    "sig_meters = sig\n",
    "''';\n",
    "\n",
    "# another way to get these varibles is just use the accessor functions for the gridmod3d.  We need them later.\n",
    "xmin = other_pars['xmin']\n",
    "dx   = other_pars['dx']\n",
    "nx   = other_pars['nx']\n",
    "ymin = other_pars['ymin']\n",
    "dy   = other_pars['dy']\n",
    "ny   = other_pars['ny']\n",
    "zmin = other_pars['zmin']\n",
    "dz   = other_pars['dz']\n",
    "nz   = other_pars['nz']\n",
    "sig_meters = other_pars['sig']  # this variable is used later\n",
    "print('sig_meters:',sig_meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the spatial reference\n",
    "grid = pv.UniformGrid()\n",
    "\n",
    "# Set the grid dimensions: shape + 1 because we want to inject our values on\n",
    "#   the CELL data\n",
    "nam_dims = list(vslice_gm3d.get_npoints())\n",
    "nam_origin = [0,0,-vslice_gm3d.get_gorigin()[2]]\n",
    "#nam_origin = list(vslice_gm3d.get_gorigin())\n",
    "#nam_origin[2] *= -1\n",
    "nam_origin = tuple(nam_origin)\n",
    "nam_spacing = list(vslice_gm3d.get_deltas())\n",
    "nam_spacing[2] *=-1\n",
    "nam_spacing = tuple(nam_spacing)\n",
    "print('nam_dims:',nam_dims)\n",
    "print('nam_origin:',nam_origin)\n",
    "print('nam_spacing:',nam_spacing)\n",
    "\n",
    "# Edit the spatial reference\n",
    "grid.dimensions = np.array(nam_dims) + 1\n",
    "grid.origin = nam_origin  # The bottom left corner of the data set\n",
    "grid.spacing = nam_spacing  # These are the cell sizes along each axis\n",
    "nam_pvalues = vslice_gm3d.getNPArray()[0]\n",
    "print('pvalues.shape:',nam_pvalues.shape)\n",
    "\n",
    "# Add the data values to the cell data\n",
    "grid.cell_arrays[\"values\"] = nam_pvalues.flatten(order=\"F\")  # Flatten the array!\n",
    "\n",
    "# Now plot the grid!\n",
    "cmap = plt.cm.jet\n",
    "#grid.plot(show_edges=True,cmap=cmap)\n",
    "grid.plot(cmap=cmap,opacity=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = grid.slice_orthogonal()\n",
    "\n",
    "#slices.plot(show_edges=True,cmap=cmap)\n",
    "slices.plot(cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create random virtual source (to specfem stations, but using reciprocity -- sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coords = vslice_gm3d.getGlobalCoordsPointsXYZ()\n",
    "coords = vslice_gm3d.getLocalCoordsPointsXYZ()\n",
    "coords[:,2] = -coords[:,2]\n",
    "\n",
    "xc = np.unique(coords.T[0,:])\n",
    "yc = np.unique(coords.T[1,:])\n",
    "zc = np.unique(coords.T[2,:])\n",
    "\n",
    "\n",
    "#n_rand_p = 1000\n",
    "\n",
    "n_rand_p = 3\n",
    "np.random.seed(n_rand_p) #nothing special about using n_rand_p just want reproducible random\n",
    "\n",
    "#stay away from the edges of the model for derivatives \n",
    "# and to avoid boundary effects\n",
    "xy_pad = 500 \n",
    "\n",
    "lrx = np.min(xc) + xy_pad\n",
    "lry = np.min(yc) + xy_pad\n",
    "lrz = -3400.0\n",
    "\n",
    "hrx = np.max(xc) - xy_pad\n",
    "hry = np.max(yc) - xy_pad\n",
    "hrz = -2600.0\n",
    "\n",
    "srx = hrx - lrx\n",
    "sry = hry - lry\n",
    "srz = hrz - lrz\n",
    "\n",
    "r_xyz_list = []\n",
    "for i in range(n_rand_p):\n",
    "    rx = lrx + srx*np.random.rand()\n",
    "    ry = lry + sry*np.random.rand()\n",
    "    rz = lrz + srz*np.random.rand()\n",
    "    r_xyz_list.append([rx,ry,rz])\n",
    "    \n",
    "r_xyz = np.array(r_xyz_list)\n",
    "    \n",
    "\n",
    "#r_xyz = np.vstack(np.meshgrid(rx,ry,rz)).reshape(3,-1).T\n",
    "print('r_xyz:\\n',r_xyz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_rpoints = pv.wrap(r_xyz)\n",
    "p = pv.Plotter()\n",
    "slices = grid.slice_orthogonal()\n",
    "#p.add_mesh(slices,cmap=cmap,opacity=0.50)\n",
    "p.add_mesh(slices,cmap=cmap,opacity=1)\n",
    "p.add_mesh(grid,cmap=cmap,opacity=0.50)\n",
    "p.add_mesh(pv_rpoints, render_points_as_spheres=True, point_size=5,opacity=1.0)\n",
    "\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Moment Tensors and CMTSolutionHeaders for each tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is the path to the project dir on the cluster\n",
    "my_proj_dir = '/scratch/seismology/tcullison/test_mesh/FWD_Batch_Src_Test'\n",
    "\n",
    "magnitude = np.pi\n",
    "strike = [30,45,90] # just making three to test\n",
    "dip = [30,30,60]\n",
    "rake = [330,190,20]\n",
    "\n",
    "l_mt = []\n",
    "for i in range(len(strike)):\n",
    "    l_mt.append(MomentTensor(mw=magnitude,strike=strike[i],dip=dip[i],rake=rake[i]))\n",
    "\n",
    "assert len(l_mt) == len(r_xyz)\n",
    "\n",
    "for mt in l_mt:\n",
    "    print(f'mt:\\n{mt}')\n",
    "    \n",
    "l_cmt_srcs = []\n",
    "for i in range(len(r_xyz)):\n",
    "    cmt_h = CMTSolutionHeader(date=datetime.datetime.now(),\n",
    "                              ename=f'Event-{str(i).zfill(4)}',\n",
    "                              tshift=0.0,\n",
    "                              hdur=0.0,\n",
    "                              lat_yc=r_xyz[i,1],\n",
    "                              lon_xc=r_xyz[i,0],\n",
    "                              depth=-r_xyz[i,2],\n",
    "                              mt=l_mt[i],\n",
    "                              eid=i,\n",
    "                              sid=0)\n",
    "    l_cmt_srcs.append(cmt_h)\n",
    "    \n",
    "print()\n",
    "for cmt in l_cmt_srcs:\n",
    "    print(f'cmt:\\n{cmt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Corresponding \"Virtual\" Recievers (including cross membors for derivatives) for the CMT's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_delta = 50.0 # distance between cross stations for derivatives\n",
    "assert m_delta < xy_pad #see cells above this is padding\n",
    "#l_grp_vrecs = make_grouped_half_cross_reciprocal_station_headers_from_cmt_list(l_cmt_srcs,m_delta)\n",
    "l_grp_vrecs = make_grouped_cross_reciprocal_station_headers_from_cmt_list(l_cmt_srcs,m_delta)\n",
    "\n",
    "ig = 0\n",
    "for grp in l_grp_vrecs:\n",
    "    print(f'***** Group: {ig} *****\\n')\n",
    "    ir = 0\n",
    "    for gvrec in grp:\n",
    "        print(f'*** vrec: {ir} ***\\n{gvrec}')\n",
    "        ir += 1\n",
    "    ig += 1\n",
    "\n",
    "print(len(flatten_grouped_headers(l_grp_vrecs)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Virtual Receiver Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_g_xyz = get_xyz_coords_from_station_list(flatten_grouped_headers(l_grp_vrecs))\n",
    "all_g_xyz[:,2] *= -1 #pyview z-up positive and oposize sign of standard geophysics \n",
    "pv_all_points = pv.wrap(all_g_xyz)\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(grid,cmap=cmap,opacity=0.5)\n",
    "p.add_mesh(slices,cmap=cmap,opacity=1.0)\n",
    "p.add_mesh(pv_all_points, render_points_as_spheres=True, point_size=5,opacity=1.0)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get receiver/station coordinates created from a different notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickle the Bounding box (from a different notebook)\n",
    "\n",
    "#ifqn  = data_out_dir + 'bbox_nvl' + str(int(nvl)) + '_nvb' + str(int(nvb))\n",
    "#ifqn += '_xsft' + str(xshift) + '_ysft' + str(yshift) + '.pickle'\n",
    "ifqn = data_out_dir + 'bbox_nvl152_nvb197_xsft4400_ysft19100.pickle'\n",
    "f = open(ifqn, 'rb')\n",
    "sgf_bbox = pickle.load(f)\n",
    "f.close()\n",
    "print()\n",
    "print('Unpickled Bounding:\\n',sgf_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickle the events if needed (again from a different notebook)\n",
    "ifqn = data_out_dir + 'bbox_groning_events.pickle'\n",
    "f = open(ifqn, 'rb')\n",
    "bbox_events = pickle.load(f)\n",
    "f.close()\n",
    "print()\n",
    "print('Unpickled Events:\\n',bbox_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read moment tensors\n",
    "mt_in_file  = 'data/groningen/events/event_moments.csv' \n",
    "!ls {mt_in_file}\n",
    "bbox_gf_mts = mtensors(mt_in_file)\n",
    "\n",
    "# get event catalog of the events (ObsPy catalog)\n",
    "bbox_event_cat = copy.deepcopy(bbox_events.getIncCatalog())\n",
    "\n",
    "# This is a bit hokey, but it works. Here we update the\n",
    "# event time from the moment tensor CSV file with thouse\n",
    "# from the event catalog\n",
    "bbox_gf_mts.update_utcdatetime(bbox_event_cat)\n",
    "\n",
    "'''\n",
    "#for imt in range(len(bbox_gf_mts)):\n",
    "#    print(\"Moment-Tensor %d:/n\" %(imt),bbox_gf_mts[imt])\n",
    "'''\n",
    "\n",
    "# Create a dictionary that maps moment tensors to events\n",
    "bbox_emap,bbox_mt_cat,bbox_mts = bbox_gf_mts.get_intersect_map_events_mts(bbox_event_cat)\n",
    "bbox_e2mt_keys = bbox_emap.keys()\n",
    "\n",
    "# Print a comparison of events to moment tensors\n",
    "for key in bbox_e2mt_keys:\n",
    "    print('UTC: event[%d][Date] = %s' %(key,bbox_mt_cat[key].origins[0].time))\n",
    "    print('UTC:    MT[%d][Date] = %s' %(key,bbox_emap[key]['Date']))\n",
    "    print('Mag: event[%d][Date] = %s' %(key,bbox_mt_cat[key].magnitudes[0].mag))\n",
    "    print('Mag:    MT[%d][Date] = %s' %(key,bbox_emap[key]['ML']))\n",
    "    print()\n",
    "\n",
    "#replace moment-tensors with only those that intersect with the events in the BoundingBox\n",
    "bbox_gf_mts.replace_moment_tensors_from_map(bbox_emap)\n",
    "    \n",
    "# add mt_catalog to bbox_events\n",
    "bbox_events.mergeMomentTensorsCatalog(bbox_mt_cat)\n",
    "merged_bbox_event_cat = bbox_events.getIncCatalog()\n",
    "print('bbox_event_cat:\\n', bbox_event_cat)\n",
    "print()\n",
    "print('merged_bbox_event_cat:\\n', merged_bbox_event_cat)\n",
    "print()\n",
    "print('bbox_mt_cat:\\n', bbox_mt_cat)\n",
    "print()\n",
    "print('bbox_mt_df:\\n', bbox_gf_mts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifqn = data_out_dir + 'bbox_groning_stations.pickle'\n",
    "\n",
    "print('Unpickling Station Traces')\n",
    "f = open(ifqn, 'rb')\n",
    "bbox_straces = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "print('Stations:\\n',type(bbox_straces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read shapefiles\n",
    "shape_in_files  = 'data/groningen/shapefile/Groningen_field' \n",
    "\n",
    "gf_shape = sf.Reader(shape_in_files)\n",
    "print('Groningen Field shape:',gf_shape)\n",
    "\n",
    "#get coordinates for the Shape-File\n",
    "s = gf_shape.shape(0)\n",
    "shape_xy = np.asarray(s.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is kind of hokey, but it works for now.\n",
    "# Some of the stations depths do not follow the \n",
    "# 50, 100, 150, 200 meter depths -- possibly because\n",
    "# the boreholes are slanted. To correct for this,\n",
    "# a hard coded \"patch/update\" is applied. See the\n",
    "# code for details and update values.\n",
    "#from gnam.events.munge.knmi import correct_station_depths as csd_f\n",
    "bbox_straces.correct_stations(csd_f)\n",
    "\n",
    "bbox_bb_diam = 1500  #size of the beachball for plotting. I had to play with this parameter\n",
    "bbox_cmt_bballs = bbox_gf_mts.get_cmt_beachballs(diam=bbox_bb_diam,fc='black')\n",
    "\n",
    "bbox_mt_coords = bbox_events.getIncCoords()\n",
    "\n",
    "#get event and borhole keys used for indexing\n",
    "ekeys = bbox_straces.getEventKeys()\n",
    "bkeys = bbox_straces.getBoreholeKeys()\n",
    "\n",
    "#Plot seuence of events with stations \n",
    "#for ie in ekeys:\n",
    "for i in range(1):\n",
    "    ie = ekeys[i]\n",
    "    # coordinates for stations that are in the bounding box\n",
    "    xy3 = bbox_straces.getIncStationCoords(ie,bkeys[0]) #station code G##3\n",
    "    xy4 = bbox_straces.getIncStationCoords(ie,bkeys[1]) #station code G##4\n",
    "    \n",
    "    # coordinates for stations that are G-stations but outside the bounding box\n",
    "    ex_xy3 = bbox_straces.getExcStationCoords(ie,bkeys[0]) #station code G##3\n",
    "    ex_xy4 = bbox_straces.getExcStationCoords(ie,bkeys[1]) #station code G##4\n",
    "    \n",
    "    # coordinates for stations that are inside the bounding box but there is no data\n",
    "    er_xy3 = bbox_straces.getErrStationCoords(ie,bkeys[0]) #station code G##3\n",
    "    er_xy4 = bbox_straces.getErrStationCoords(ie,bkeys[1]) #station code G##4\n",
    "\n",
    "    fig, ax = plt.subplots(1,figsize=(8,8))\n",
    "    fig.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    #Groningen Field Shape-File\n",
    "    ax.scatter(shape_xy[:,0],shape_xy[:,1],s=1,c='black',zorder=0)\n",
    "    \n",
    "    #Bounding Box\n",
    "    ax.plot(sgf_bbox.getCLoop()[:,0],sgf_bbox.getCLoop()[:,1],c='green',zorder=1)\n",
    "    \n",
    "    #Events (reuse event coordinates from cell further above)\n",
    "    ax.scatter(bbox_mt_coords[ie,0],bbox_mt_coords[ie,1],s=90,c='red',marker='*',zorder=5)\n",
    "    beach = bbox_cmt_bballs[ie]  #this creates a plot collection for the beachball points\n",
    "    beach.set_zorder(3)\n",
    "    ax.add_collection(beach)\n",
    "    \n",
    "    #Included stations\n",
    "    ax.scatter(xy3[:,0],xy3[:,1],s=50,c='blue',marker='v',zorder=3)\n",
    "    ax.scatter(xy4[:,0],xy4[:,1],s=100,c='gray',marker='o',zorder=2)\n",
    "    \n",
    "    #Excluded stations\n",
    "    ax.scatter(ex_xy3[:,0],ex_xy3[:,1],s=80,c='lightgray',marker='1',zorder=4)\n",
    "    ax.scatter(ex_xy4[:,0],ex_xy4[:,1],s=100,c='lightgray',marker='2',zorder=3)\n",
    "    \n",
    "    #Stations without data\n",
    "    ax.scatter(er_xy3[:,0],er_xy3[:,1],s=50,c='yellow',marker='v',zorder=4)\n",
    "    ax.scatter(er_xy4[:,0],er_xy4[:,1],s=100,c='gray',marker='o',zorder=3)\n",
    "    \n",
    "    origin_time = bbox_events[ie].origins[0].time\n",
    "    mag = bbox_events[ie].magnitudes[0].mag\n",
    "    title_str = 'Event-%d, Origin Time: %s, Magnitude: %1.2f' %(ie,str(origin_time),mag)\n",
    "    ax.set_title(title_str)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(1,figsize=(8,8))\n",
    "fig1.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "#Groningen Field Shape-File\n",
    "ax1.scatter(shape_xy[:,0],shape_xy[:,1],s=1,c='black',zorder=0)\n",
    "\n",
    "#Bounding Box\n",
    "ax1.plot(sgf_bbox.getCLoop()[:,0],sgf_bbox.getCLoop()[:,1],c='green',zorder=1)\n",
    "\n",
    "#Events (reuse event coordinates from cell further above)\n",
    "ax1.scatter(bbox_mt_coords[ie,0],bbox_mt_coords[ie,1],s=90,c='red',marker='*',zorder=5)\n",
    "    \n",
    "all_xy4 = np.concatenate((xy4,er_xy4),axis=0)\n",
    "#all_xy4 = xy4\n",
    "\n",
    "ax1.scatter(all_xy4[:,0],all_xy4[:,1],s=100,c='gray',marker='o',zorder=2)\n",
    "ax1.scatter(er_xy4[:,0],er_xy4[:,1],s=100,c='yellow',marker='x',zorder=2)\n",
    "\n",
    "title_str = 'Event-%d, Origin Time: %s, Magnitude: %1.2f' %(ie,str(origin_time),mag)\n",
    "ax1.set_title(title_str)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make random virtual sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = vslice_gm3d.getLocalCoordsPointsXY()\n",
    "\n",
    "x_orig = vslice_gm3d.get_gorigin()[0]\n",
    "y_orig = vslice_gm3d.get_gorigin()[1]\n",
    "\n",
    "clip_xy = all_xy4[9:13]\n",
    "print(clip_xy)\n",
    "\n",
    "s_xyz = np.zeros((len(clip_xy),3))\n",
    "s_xyz[:,0] = clip_xy[:,0] - x_orig\n",
    "s_xyz[:,1] = clip_xy[:,1] - y_orig\n",
    "s_xyz[:,2] = -200\n",
    "\n",
    "print(s_xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot virtual sources (red) with virtual receivers (white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_spoints = pv.wrap(s_xyz)\n",
    "p = pv.Plotter()\n",
    "#p.add_mesh(slices,cmap=cmap,opacity=0.50)\n",
    "p.add_mesh(grid,cmap=cmap,opacity=0.3)\n",
    "p.add_mesh(pv_spoints, render_points_as_spheres=True, point_size=8,opacity=1,color='red')\n",
    "#p.add_mesh(pv_rpoints, render_points_as_spheres=True, point_size=5,opacity=0.5)\n",
    "p.add_mesh(all_g_xyz, render_points_as_spheres=True, point_size=5,opacity=0.5)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make StationHeaders (real recievers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_real_recs = []\n",
    "for i in range(len(s_xyz)):\n",
    "    \n",
    "    tr_bname = 'tr'\n",
    "    new_r = StationHeader(name=tr_bname,\n",
    "                          network='NL', #FIXME\n",
    "                          lon_xc=s_xyz[i,0],\n",
    "                          lat_yc=s_xyz[i,1],\n",
    "                          depth=-s_xyz[i,2], #specfem z-down is positive\n",
    "                          elevation=0.0,\n",
    "                          trid=i)\n",
    "    l_real_recs.append(new_r)\n",
    "    \n",
    "for rec in l_real_recs:\n",
    "    print(rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ForceSolutionHeaders for the above virtual sources (including force-triplets for calculation derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_grp_vsrcs = make_grouped_reciprocal_force_solution_triplet_headers_from_rec_list(l_real_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make replicates of each virtual receiver list: one for each force-triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_grp_vrecs_by_vsrcs = make_replicated_reciprocal_station_headers_from_src_triplet_list(l_grp_vsrcs,\n",
    "                                                                                          l_grp_vrecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot virtual sources (red) and virtual receivers (white) FROM headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grp_s_xyz = get_unique_xyz_coords_from_solution_list(flatten_grouped_headers(l_grp_vsrcs))\n",
    "grp_s_xyz[:,2] *= -1 #pyvista z-up is positive\n",
    "\n",
    "flat_recs = flatten_grouped_headers(flatten_grouped_headers(l_grp_vrecs_by_vsrcs))\n",
    "grp_r_xyz = get_unique_xyz_coords_from_station_list(flat_recs)\n",
    "grp_r_xyz[:,2] *= -1 #pyvista z-up is positive\n",
    "\n",
    "print(len(grp_s_xyz))\n",
    "print(len(grp_r_xyz))\n",
    "\n",
    "pv_spoints = pv.wrap(grp_s_xyz)\n",
    "pv_rpoints = pv.wrap(grp_r_xyz)\n",
    "\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(slices,cmap=cmap,opacity=0.50)\n",
    "p.add_mesh(grid,cmap=cmap,opacity=0.3)\n",
    "p.add_mesh(pv_spoints, render_points_as_spheres=True, point_size=8,opacity=1,color='red')\n",
    "p.add_mesh(pv_rpoints, render_points_as_spheres=True, point_size=5,opacity=0.5)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make replicates of each \"real\" receiver list: for each CMT source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_grp_recs_by_srcs = make_replicated_station_headers_from_src_list(l_cmt_srcs,l_real_recs)\n",
    "\n",
    "\n",
    "for i in range(len(l_cmt_srcs)):\n",
    "    print(f'***** SRC Records for Source: {i} *****\\n')\n",
    "    for j in range(len(l_real_recs)):\n",
    "        print(f'*** REC Header for Receiver: {j} ***\\n{l_grp_recs_by_srcs[i][j]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot \"real\" sources (red) and virtual receivers (white) FROM headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_s_xyz = get_unique_xyz_coords_from_solution_list(l_cmt_srcs)\n",
    "grp_s_xyz[:,2] *= -1 #pyvista z-up is positive\n",
    "\n",
    "flat_recs = flatten_grouped_headers(l_grp_recs_by_srcs) #real!\n",
    "grp_r_xyz = get_unique_xyz_coords_from_station_list(flat_recs)\n",
    "grp_r_xyz[:,2] *= -1 #pyvista z-up is positive\n",
    "\n",
    "print(len(grp_s_xyz))\n",
    "print(len(grp_r_xyz))\n",
    "\n",
    "pv_spoints = pv.wrap(grp_s_xyz)\n",
    "pv_rpoints = pv.wrap(grp_r_xyz)\n",
    "\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(slices,cmap=cmap,opacity=0.50)\n",
    "p.add_mesh(grid,cmap=cmap,opacity=0.3)\n",
    "p.add_mesh(pv_spoints, render_points_as_spheres=True, point_size=12,opacity=1,color='red')\n",
    "p.add_mesh(pv_rpoints, render_points_as_spheres=True, point_size=8,opacity=0.5)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make reciprical RecordHeader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_flat_vsrcs = flatten_grouped_headers(l_grp_vsrcs)\n",
    "l_flat_vrecs = flatten_grouped_headers(flatten_grouped_headers(l_grp_vrecs_by_vsrcs))\n",
    "\n",
    "vrecord_h = RecordHeader(name='Reciprocal-Record',solutions_h=l_flat_vsrcs,stations_h=l_flat_vrecs)\n",
    "\n",
    "# save the header to disc\n",
    "vrec_fqp = os.path.join(data_out_dir,'simple_record_h')\n",
    "_write_header(vrec_fqp,vrecord_h)\n",
    "\n",
    "#verify file is there\n",
    "!ls -l {vrec_fqp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make reciprocal project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_proj_name = 'ReciprocalTestProject'\n",
    "test_proj_root_fqp =  os.path.join(data_out_dir, 'tmp/TestProjects/NewMKProj')\n",
    "test_parfile_fqp =  os.path.join(data_out_dir, 'Par_file')\n",
    "test_mesh_fqp = '/scratch/seismology/tcullison/test_mesh/MESH-default_batch_force_src'\n",
    "test_spec_fqp = '/quanta1/home/tcullison/DevGPU_specfem3d'\n",
    "test_pyutils_fqp = '/quanta1/home/tcullison/myscripts/python/specfem/pyutils'\n",
    "test_script_fqp = '/quanta1/home/tcullison/myscripts/specfem'\n",
    "\n",
    "#copy the reciprocal record\n",
    "test_proj_record_h = vrecord_h.copy()\n",
    "\n",
    "make_fwd_project_dir(test_proj_name,\n",
    "                     test_proj_root_fqp,\n",
    "                     test_parfile_fqp,\n",
    "                     test_mesh_fqp,\n",
    "                     test_spec_fqp,\n",
    "                     test_pyutils_fqp,\n",
    "                     test_script_fqp,\n",
    "                     test_proj_record_h,\n",
    "                     batch_srcs=False,\n",
    "                     verbose=True,\n",
    "                     max_event_rdirs=MAX_SPEC_SRC)\n",
    "                     #max_event_rdirs=)\n",
    "        \n",
    "\n",
    "print()\n",
    "print('ls:')\n",
    "!ls {test_proj_root_fqp}\n",
    "print('ls:')\n",
    "!ls {test_proj_root_fqp}/*/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Forward/Real RecordHeader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_flat_srcs = l_cmt_srcs #NOTE: we don't need to flatten CMT list because they are not grouped\n",
    "l_flat_recs = flatten_grouped_headers(l_grp_recs_by_srcs) #Note: only one level of flattening\n",
    "\n",
    "record_h = RecordHeader(name='Forward-Record',solutions_h=l_flat_srcs,stations_h=l_flat_recs)\n",
    "\n",
    "# save the header to disc\n",
    "rec_fqp = os.path.join(data_out_dir,'real_simple_record_h')\n",
    "_write_header(rec_fqp,record_h)\n",
    "\n",
    "#verify file is there\n",
    "!ls -l {rec_fqp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make \"real\" project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real_proj_name = 'ForwardTestProject'\n",
    "test_proj_root_fqp =  os.path.join(data_out_dir, 'tmp/TestProjects/NewMKProj')\n",
    "test_parfile_fqp =  os.path.join(data_out_dir, 'Par_file')\n",
    "test_mesh_fqp = '/scratch/seismology/tcullison/test_mesh/MESH-default_batch_force_src'\n",
    "test_spec_fqp = '/quanta1/home/tcullison/DevGPU_specfem3d'\n",
    "test_pyutils_fqp = '/quanta1/home/tcullison/myscripts/python/specfem/pyutils'\n",
    "test_script_fqp = '/quanta1/home/tcullison/myscripts/specfem'\n",
    "\n",
    "#copy the forward/real record\n",
    "test_real_proj_record_h = record_h.copy()\n",
    "\n",
    "make_fwd_project_dir(test_real_proj_name,\n",
    "                     test_proj_root_fqp,\n",
    "                     test_parfile_fqp,\n",
    "                     test_mesh_fqp,\n",
    "                     test_spec_fqp,\n",
    "                     test_pyutils_fqp,\n",
    "                     test_script_fqp,\n",
    "                     test_real_proj_record_h,\n",
    "                     batch_srcs=False,\n",
    "                     verbose=True,\n",
    "                     max_event_rdirs=MAX_SPEC_SRC)\n",
    "                     #max_event_rdirs=2)\n",
    "\n",
    "\n",
    "print()\n",
    "print('ls:')\n",
    "!ls {test_proj_root_fqp}\n",
    "print('ls:')\n",
    "!ls {test_proj_root_fqp}/*/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
